{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Configuraci√≥n del estilo de las gr√°ficas\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "\n",
    "def ejecutar_pruebas():\n",
    "    \"\"\"Ejecuta todas las pruebas de rendimiento y muestra los resultados\"\"\"\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"COMPARATIVA DE RENDIMIENTO: GPU vs CPU PARA C√ÅLCULOS MATRICIALES\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Verificar si hay GPU disponible\n",
    "    cuda_disponible = torch.cuda.is_available()\n",
    "    if cuda_disponible:\n",
    "        dispositivo_gpu = torch.cuda.get_device_name(0)\n",
    "        print(f\"\\n‚úÖ GPU detectada: {dispositivo_gpu}\")\n",
    "        print(f\"   Versi√≥n CUDA: {torch.version.cuda}\")\n",
    "    else:\n",
    "        print(\"\\n‚ùå No se detect√≥ ninguna GPU. Solo se ejecutar√°n pruebas en CPU.\")\n",
    "        print(\"   Para usar GPU, aseg√∫rate de tener instalado PyTorch con soporte CUDA.\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\" * 80)\n",
    "    print(\"INFORMACI√ìN DEL SISTEMA\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # Obtener informaci√≥n del sistema\n",
    "    import platform\n",
    "    import psutil\n",
    "    import cpuinfo\n",
    "    \n",
    "    info_cpu = cpuinfo.get_cpu_info()\n",
    "    \n",
    "    info_sistema = [\n",
    "        [\"Sistema Operativo\", platform.platform()],\n",
    "        [\"CPU\", info_cpu.get('brand_raw', platform.processor())],\n",
    "        [\"N√∫cleos F√≠sicos\", psutil.cpu_count(logical=False)],\n",
    "        [\"N√∫cleos Totales\", psutil.cpu_count()],\n",
    "        [\"RAM Total\", f\"{psutil.virtual_memory().total / (1024**3):.2f} GB\"],\n",
    "    ]\n",
    "    \n",
    "    if cuda_disponible:\n",
    "        info_sistema.append([\"GPU\", dispositivo_gpu])\n",
    "        info_sistema.append([\"Memoria GPU\", f\"{torch.cuda.get_device_properties(0).total_memory / (1024**3):.2f} GB\"])\n",
    "        info_sistema.append([\"Versi√≥n CUDA\", torch.version.cuda])\n",
    "    \n",
    "    # Mostrar informaci√≥n del sistema\n",
    "    print(tabulate(info_sistema, tablefmt=\"simple\"))\n",
    "    \n",
    "    # Definir tama√±os de matrices a probar\n",
    "    tama√±os = [500, 1000, 2000, 4000, 6000, 8000]\n",
    "    resultados = []\n",
    "    \n",
    "    print(\"\\n\" + \"-\" * 80)\n",
    "    print(\"PRUEBAS DE RENDIMIENTO: MULTIPLICACI√ìN DE MATRICES\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # Realizar pruebas para cada tama√±o\n",
    "    for tama√±o in tama√±os:\n",
    "        print(f\"\\nPrueba con matrices de {tama√±o}x{tama√±o}:\")\n",
    "        \n",
    "        # Crear matrices de prueba\n",
    "        A_np = np.random.rand(tama√±o, tama√±o).astype(np.float32)\n",
    "        B_np = np.random.rand(tama√±o, tama√±o).astype(np.float32)\n",
    "        \n",
    "        # ----- Prueba en CPU (NumPy) -----\n",
    "        print(f\"  üîÑ Ejecutando en CPU...\", end=\"\", flush=True)\n",
    "        \n",
    "        # Calentamiento para CPU\n",
    "        _ = np.matmul(A_np, B_np)\n",
    "        \n",
    "        # Medir tiempo en CPU\n",
    "        inicio_cpu = time.time()\n",
    "        C_np = np.matmul(A_np, B_np)\n",
    "        tiempo_cpu = time.time() - inicio_cpu\n",
    "        \n",
    "        print(f\" completado en {tiempo_cpu:.4f} segundos\")\n",
    "        \n",
    "        # ----- Prueba en GPU (PyTorch) -----\n",
    "        tiempo_gpu = float('nan')  # Valor predeterminado si no hay GPU\n",
    "        aceleracion = float('nan')\n",
    "        \n",
    "        if cuda_disponible:\n",
    "            print(f\"  üîÑ Ejecutando en GPU...\", end=\"\", flush=True)\n",
    "            \n",
    "            # Convertir a tensores de PyTorch y mover a GPU\n",
    "            A_torch = torch.from_numpy(A_np).to('cuda')\n",
    "            B_torch = torch.from_numpy(B_np).to('cuda')\n",
    "            \n",
    "            # Calentamiento para GPU (primera ejecuci√≥n suele ser m√°s lenta)\n",
    "            _ = torch.matmul(A_torch, B_torch)\n",
    "            torch.cuda.synchronize()\n",
    "            \n",
    "            # Medir tiempo en GPU\n",
    "            inicio_gpu = time.time()\n",
    "            C_torch = torch.matmul(A_torch, B_torch)\n",
    "            torch.cuda.synchronize()  # Esperar a que la operaci√≥n en GPU termine\n",
    "            tiempo_gpu = time.time() - inicio_gpu\n",
    "            \n",
    "            # Calcular aceleraci√≥n\n",
    "            aceleracion = tiempo_cpu / tiempo_gpu\n",
    "            \n",
    "            print(f\" completado en {tiempo_gpu:.4f} segundos\")\n",
    "            print(f\"  ‚ö° Aceleraci√≥n GPU vs CPU: {aceleracion:.2f}x\")\n",
    "            \n",
    "            # Verificar que los resultados sean similares (opcional)\n",
    "            C_torch_cpu = C_torch.cpu().numpy()\n",
    "            error_relativo = np.mean(np.abs(C_np - C_torch_cpu) / (np.abs(C_np) + 1e-10))\n",
    "            print(f\"  ‚úì Error relativo: {error_relativo:.2e} (debe ser cercano a cero)\")\n",
    "        \n",
    "        # Guardar resultados\n",
    "        resultados.append({\n",
    "            'tama√±o': tama√±o,\n",
    "            'tiempo_cpu': tiempo_cpu,\n",
    "            'tiempo_gpu': tiempo_gpu if cuda_disponible else None,\n",
    "            'aceleracion': aceleracion if cuda_disponible else None\n",
    "        })\n",
    "    \n",
    "    # ----- Mostrar resultados en forma de tabla -----\n",
    "    print(\"\\n\" + \"-\" * 80)\n",
    "    print(\"RESUMEN DE RESULTADOS\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    tabla_datos = []\n",
    "    for r in resultados:\n",
    "        if cuda_disponible:\n",
    "            tabla_datos.append([\n",
    "                r['tama√±o'], \n",
    "                f\"{r['tiempo_cpu']:.4f}s\", \n",
    "                f\"{r['tiempo_gpu']:.4f}s\", \n",
    "                f\"{r['aceleracion']:.2f}x\"\n",
    "            ])\n",
    "        else:\n",
    "            tabla_datos.append([\n",
    "                r['tama√±o'], \n",
    "                f\"{r['tiempo_cpu']:.4f}s\", \n",
    "                \"N/A\", \n",
    "                \"N/A\"\n",
    "            ])\n",
    "    \n",
    "    headers = [\"Tama√±o Matriz\", \"Tiempo CPU\", \"Tiempo GPU\", \"Aceleraci√≥n\"]\n",
    "    print(tabulate(tabla_datos, headers=headers, tablefmt=\"simple\"))\n",
    "    \n",
    "    # ----- Generar gr√°ficas de rendimiento -----\n",
    "    if cuda_disponible:\n",
    "        generar_graficas(resultados)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"AN√ÅLISIS COMPLETADO\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Interpretaci√≥n de resultados\n",
    "    print(\"\\nInterpretaci√≥n de los resultados:\")\n",
    "    \n",
    "    if cuda_disponible:\n",
    "        aceleracion_promedio = sum(r['aceleracion'] for r in resultados) / len(resultados)\n",
    "        max_aceleracion = max(r['aceleracion'] for r in resultados)\n",
    "        tama√±o_max_aceleracion = resultados[[r['aceleracion'] for r in resultados].index(max_aceleracion)]['tama√±o']\n",
    "        \n",
    "        print(f\"\\n1. La GPU proporciona una aceleraci√≥n promedio de {aceleracion_promedio:.2f}x respecto a la CPU.\")\n",
    "        print(f\"2. La m√°xima aceleraci√≥n ({max_aceleracion:.2f}x) se observ√≥ con matrices de {tama√±o_max_aceleracion}x{tama√±o_max_aceleracion}.\")\n",
    "        print(\"3. La ventaja de la GPU es m√°s notable con matrices grandes, donde el paralelismo es m√°s efectivo.\")\n",
    "        print(\"4. Para matrices peque√±as, la sobrecarga de transferir datos a la GPU puede reducir el beneficio.\")\n",
    "    else:\n",
    "        print(\"\\n1. No se detect√≥ GPU para realizar comparaciones.\")\n",
    "        print(\"2. Los tiempos de CPU aumentan de forma cuadr√°tica o c√∫bica con el tama√±o de la matriz.\")\n",
    "        print(\"3. Para c√°lculos intensivos con matrices grandes, una GPU podr√≠a ofrecer mejoras significativas.\")\n",
    "\n",
    "def generar_graficas(resultados):\n",
    "    \"\"\"Genera gr√°ficas comparativas de rendimiento\"\"\"\n",
    "    \n",
    "    tama√±os = [r['tama√±o'] for r in resultados]\n",
    "    tiempos_cpu = [r['tiempo_cpu'] for r in resultados]\n",
    "    tiempos_gpu = [r['tiempo_gpu'] for r in resultados]\n",
    "    aceleraciones = [r['aceleracion'] for r in resultados]\n",
    "    \n",
    "    # Figura principal con dos subgr√°ficas\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Gr√°fica 1: Tiempos de ejecuci√≥n\n",
    "    ax1.plot(tama√±os, tiempos_cpu, 'o-', color='#E24A33', linewidth=2, label='CPU (NumPy)')\n",
    "    ax1.plot(tama√±os, tiempos_gpu, 'o-', color='#348ABD', linewidth=2, label='GPU (PyTorch)')\n",
    "    ax1.set_xlabel('Tama√±o de Matriz')\n",
    "    ax1.set_ylabel('Tiempo (segundos)')\n",
    "    ax1.set_title('Tiempos de Ejecuci√≥n: CPU vs GPU')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.legend()\n",
    "    \n",
    "    # Gr√°fica 2: Aceleraci√≥n\n",
    "    ax2.bar(tama√±os, aceleraciones, color='#7A68A6', alpha=0.7)\n",
    "    ax2.axhline(y=1, color='r', linestyle='--', alpha=0.5)\n",
    "    ax2.set_xlabel('Tama√±o de Matriz')\n",
    "    ax2.set_ylabel('Aceleraci√≥n (veces m√°s r√°pido)')\n",
    "    ax2.set_title('Aceleraci√≥n GPU vs CPU')\n",
    "    for i, v in enumerate(aceleraciones):\n",
    "        ax2.text(tama√±os[i], v + 0.2, f\"{v:.1f}x\", ha='center', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('comparativa_gpu_cpu.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n‚úÖ Gr√°fica guardada como 'comparativa_gpu_cpu.png'\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ejecutar_pruebas()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
